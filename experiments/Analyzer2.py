# =========================
# Analyzer1.py  (Auto Insights + Optional Chat)
# =========================

import os
import re
import json
import requests
import pandas as pd
import duckdb
import streamlit as st

# =========================
# Page config
# =========================
st.set_page_config(
    page_title="è¿è¥æ¼æ–—æ´å¯Ÿï¼ˆRetailRocketï¼‰",
    layout="wide"
)

# =========================
# ğŸ”§ å¼ºåŠ›å…œåº•ï¼šä¿®å¤æ»šåŠ¨æ¡é—®é¢˜
# =========================
st.markdown("""
<style>
html, body {
  overflow: auto !important;
  height: auto !important;
}
[data-testid="stAppViewContainer"] {
  overflow: auto !important;
}
/* é˜²æ­¢ fixed + 100vw è¦†ç›–æ»šåŠ¨æ¡ */
[data-testid="stChatInput"],
[data-testid="stHeader"],
[data-testid="stToolbar"],
[data-testid="stMain"],
[data-testid="stSidebar"] {
  width: 100% !important;
  box-sizing: border-box !important;
}
</style>
""", unsafe_allow_html=True)

# =========================
# DeepSeek Config
# =========================
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
DEEPSEEK_BASE_URL = "https://api.deepseek.com"
CHAT_MODEL = "deepseek-chat"
REASONER_MODEL = "deepseek-reasoner"

# =========================
# Utils
# =========================
def deepseek_chat(messages, model, json_mode=False, temperature=0.3):
    if not DEEPSEEK_API_KEY:
        raise RuntimeError("Missing DEEPSEEK_API_KEY. Please set environment variable DEEPSEEK_API_KEY.")

    headers = {
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": model,
        "messages": messages,
        "temperature": temperature
    }
    if json_mode:
        payload["response_format"] = {"type": "json_object"}

    r = requests.post(
        f"{DEEPSEEK_BASE_URL}/chat/completions",
        headers=headers,
        json=payload,
        timeout=120
    )
    r.raise_for_status()
    return r.json()["choices"][0]["message"]["content"]


def extract_json(text):
    try:
        return json.loads(text)
    except Exception:
        pass
    m = re.search(r"\{[\s\S]*\}", text)
    if not m:
        return None
    try:
        return json.loads(m.group(0))
    except Exception:
        return None


def run_sql(con, sql_query, max_rows=200):
    cleaned = sql_query.strip().rstrip(";")
    lower = cleaned.lower()
    if not (lower.startswith("select") or lower.startswith("with")):
        raise ValueError("Only SELECT/WITH allowed")

    limited_sql = f"""
    SELECT *
    FROM (
        {cleaned}
    ) t
    LIMIT {int(max_rows)}
    """
    return con.execute(limited_sql).df()


def find_biggest_drop_pp(prev_row, last_row):
    """Return worst step and deltas in percentage points (pp). Negative means worse."""
    deltas = {
        "viewâ†’cart": (float(last_row["cr_view_to_cart"]) - float(prev_row["cr_view_to_cart"])) * 100.0,
        "cartâ†’pay":  (float(last_row["cr_cart_to_pay"])  - float(prev_row["cr_cart_to_pay"]))  * 100.0,
        "viewâ†’pay":  (float(last_row["cr_view_to_pay"])  - float(prev_row["cr_view_to_pay"]))  * 100.0,
    }
    worst_step = min(deltas, key=deltas.get)  # most negative
    return worst_step, round(deltas[worst_step], 2), deltas


# =========================
# Funnel SQL Templates (data-relative last_7d vs prev_7d)
# =========================
def compare_funnel_sql_loose(ts: str, uid: str, evt: str) -> str:
    return f"""
WITH bounds AS (
  SELECT MAX(to_timestamp({ts}/1000)) AS max_ts
  FROM events
),
base AS (
  SELECT
    {uid} AS user_id,
    {evt} AS event,
    to_timestamp({ts} / 1000) AS ts,
    CASE
      WHEN to_timestamp({ts} / 1000) >= (SELECT max_ts FROM bounds) - INTERVAL 7 DAY THEN 'last_7d'
      WHEN to_timestamp({ts} / 1000) >= (SELECT max_ts FROM bounds) - INTERVAL 14 DAY
       AND to_timestamp({ts} / 1000) <  (SELECT max_ts FROM bounds) - INTERVAL 7 DAY THEN 'prev_7d'
      ELSE NULL
    END AS period
  FROM events
  WHERE {evt} IN ('view','addtocart','transaction')
),
agg AS (
  SELECT
    period,
    COUNT(DISTINCT CASE WHEN event='view' THEN user_id END)        AS view_users,
    COUNT(DISTINCT CASE WHEN event='addtocart' THEN user_id END)   AS cart_users,
    COUNT(DISTINCT CASE WHEN event='transaction' THEN user_id END) AS pay_users
  FROM base
  WHERE period IS NOT NULL
  GROUP BY 1
)
SELECT
  period,
  view_users, cart_users, pay_users,
  cart_users * 1.0 / NULLIF(view_users,0) AS cr_view_to_cart,
  pay_users  * 1.0 / NULLIF(cart_users,0) AS cr_cart_to_pay,
  pay_users  * 1.0 / NULLIF(view_users,0) AS cr_view_to_pay
FROM agg
ORDER BY CASE period WHEN 'prev_7d' THEN 1 ELSE 2 END
"""


def compare_funnel_sql_strict(ts: str, uid: str, evt: str) -> str:
    return f"""
WITH bounds AS (
  SELECT MAX(to_timestamp({ts}/1000)) AS max_ts
  FROM events
),
filtered AS (
  SELECT
    {uid} AS user_id,
    {evt} AS event,
    to_timestamp({ts} / 1000) AS ts,
    CASE
      WHEN to_timestamp({ts} / 1000) >= (SELECT max_ts FROM bounds) - INTERVAL 7 DAY THEN 'last_7d'
      WHEN to_timestamp({ts} / 1000) >= (SELECT max_ts FROM bounds) - INTERVAL 14 DAY
       AND to_timestamp({ts} / 1000) <  (SELECT max_ts FROM bounds) - INTERVAL 7 DAY THEN 'prev_7d'
      ELSE NULL
    END AS period
  FROM events
  WHERE {evt} IN ('view','addtocart','transaction')
),
u AS (
  SELECT
    user_id,
    period,
    MIN(CASE WHEN event='view'        THEN ts END) AS t_view,
    MIN(CASE WHEN event='addtocart'   THEN ts END) AS t_cart,
    MIN(CASE WHEN event='transaction' THEN ts END) AS t_pay
  FROM filtered
  WHERE period IS NOT NULL
  GROUP BY 1,2
),
agg AS (
  SELECT
    period,
    COUNT(*) FILTER (WHERE t_view IS NOT NULL) AS view_users,
    COUNT(*) FILTER (WHERE t_view IS NOT NULL AND t_cart IS NOT NULL AND t_cart >= t_view) AS cart_users,
    COUNT(*) FILTER (
      WHERE t_view IS NOT NULL AND t_cart IS NOT NULL AND t_pay IS NOT NULL
        AND t_cart >= t_view AND t_pay >= t_cart
    ) AS pay_users
  FROM u
  GROUP BY 1
)
SELECT
  period,
  view_users, cart_users, pay_users,
  cart_users * 1.0 / NULLIF(view_users,0) AS cr_view_to_cart,
  pay_users  * 1.0 / NULLIF(cart_users,0) AS cr_cart_to_pay,
  pay_users  * 1.0 / NULLIF(view_users,0) AS cr_view_to_pay
FROM agg
ORDER BY CASE period WHEN 'prev_7d' THEN 1 ELSE 2 END
"""


# =========================
# UI - Sidebar
# =========================
st.sidebar.title("è®¾ç½®")
deep_mode = st.sidebar.toggle("æ·±åº¦åˆ†æï¼ˆreasonerï¼‰", value=False, help="å¼€å¯åå»ºè®®æ›´æ·±ä½†æ›´æ…¢")
strict_mode = st.sidebar.toggle("ä¸¥æ ¼æ¼æ–—ï¼ˆé¡ºåºï¼‰", value=False, help="ä¸¥æ ¼ï¼šå¿…é¡» viewâ†’addtocartâ†’transaction é¡ºåºæ»¡è¶³")
compare_mode = st.sidebar.toggle("å¯¹æ¯”ï¼šlast_7d vs prev_7d", value=True, help="ä»¥æ•°æ®æœ€å¤§æ—¶é—´ä¸ºåŸºå‡†åšä¸¤æ®µ 7 å¤©å¯¹æ¯”")
max_rows = st.sidebar.slider("SQL è¿”å›æœ€å¤§è¡Œæ•°", 50, 500, 200, 50)

uploaded = st.sidebar.file_uploader("ä¸Šä¼  events.csv", type=["csv"])

# =========================
# Main
# =========================
st.title("ğŸ“Š è¿è¥æ¼æ–—æ´å¯Ÿï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰")

if not uploaded:
    st.info("è¯·åœ¨å·¦ä¾§ä¸Šä¼  RetailRocket çš„ events.csv")
    st.stop()

df = pd.read_csv(uploaded)

with st.expander("æ•°æ®é¢„è§ˆ", expanded=False):
    st.dataframe(df.head(20), use_container_width=True)

# è‡ªåŠ¨è¯†åˆ«åˆ—å
cols = {c.lower(): c for c in df.columns}
ts_col = cols.get("timestamp")
uid_col = cols.get("visitorid")
evt_col = cols.get("event")

if not all([ts_col, uid_col, evt_col]):
    st.error("æœªè¯†åˆ«åˆ° timestamp / visitorid / event åˆ—")
    st.stop()

# DuckDB
con = duckdb.connect(database=":memory:")
con.register("events_df", df)
con.execute("CREATE TABLE events AS SELECT * FROM events_df")

# æ•°æ®æœ€å¤§æ—¶é—´ï¼ˆå‘Šè¯‰ç”¨æˆ·â€œæœ€è¿‘7å¤©â€æ˜¯ç›¸å¯¹æ•°æ®æ—¶é—´ï¼‰
max_ts = con.execute(f"SELECT MAX(to_timestamp({ts_col}/1000)) FROM events").fetchone()[0]
st.caption(f"æ—¶é—´çª—å£è¯´æ˜ï¼šä»¥æ•°æ®æœ€æ–°æ—¶é—´ **{max_ts}** ä¸ºåŸºå‡†ï¼Œè®¡ç®— last_7dï¼ˆæœ€è¿‘7å¤©ï¼‰ä¸ prev_7dï¼ˆå‰7å¤©ï¼‰ã€‚")

# =========================
# Run funnel (Auto)
# =========================
if not compare_mode:
    st.warning("å½“å‰ç‰ˆæœ¬ä¸ºâ€œè‡ªåŠ¨æ´å¯Ÿâ€æ¨¡å¼ï¼Œå»ºè®®å¼€å¯å¯¹æ¯”æ¨¡å¼ï¼ˆlast_7d vs prev_7dï¼‰ã€‚")
    st.stop()

sql_query = (
    compare_funnel_sql_strict(ts_col, uid_col, evt_col)
    if strict_mode else
    compare_funnel_sql_loose(ts_col, uid_col, evt_col)
)

try:
    result_df = run_sql(con, sql_query, max_rows=max_rows)
except Exception as e:
    st.error("SQL æ‰§è¡Œå¤±è´¥ï¼ˆå¯èƒ½æ˜¯åˆ—å/æ•°æ®ç±»å‹é—®é¢˜ï¼‰ã€‚")
    st.code(sql_query, language="sql")
    st.code(str(e))
    st.stop()

st.subheader("ğŸ“ˆ å¯¹æ¯”æ¼æ–—ç»“æœï¼ˆæŒ‰ç”¨æˆ·ï¼‰")
st.dataframe(result_df, use_container_width=True)

# =========================
# Auto Insight Cards
# =========================
if result_df.shape[0] < 2:
    st.warning("æœªå¾—åˆ° prev_7d ä¸ last_7d ä¸¤æœŸç»“æœï¼Œè¯·æ£€æŸ¥æ•°æ®æˆ– SQLã€‚")
    st.stop()

# ç¡®ä¿é¡ºåºï¼šprev_7d, last_7d
order = {"prev_7d": 0, "last_7d": 1}
df2 = result_df.copy()
df2["__o"] = df2["period"].map(order)
df2 = df2.sort_values("__o").drop(columns="__o")

prev = df2[df2["period"] == "prev_7d"].iloc[0]
last = df2[df2["period"] == "last_7d"].iloc[0]

def pp(a, b):
    return round((float(b) - float(a)) * 100, 2)

worst_step, worst_pp, deltas = find_biggest_drop_pp(prev, last)

st.subheader("ğŸš¨ è‡ªåŠ¨æ´å¯Ÿï¼ˆæœ¬æœŸ vs ä¸ŠæœŸï¼‰")

col1, col2, col3 = st.columns(3)
with col1:
    st.metric("æµè§ˆç”¨æˆ·ï¼ˆviewï¼‰", int(last["view_users"]), int(last["view_users"] - prev["view_users"]))
with col2:
    st.metric("åŠ è´­ç”¨æˆ·ï¼ˆaddtocartï¼‰", int(last["cart_users"]), int(last["cart_users"] - prev["cart_users"]))
with col3:
    st.metric("æˆäº¤ç”¨æˆ·ï¼ˆtransactionï¼‰", int(last["pay_users"]), int(last["pay_users"] - prev["pay_users"]))

st.markdown(f"**æœ€å¤§ä¸‹é™æ­¥éª¤**ï¼š**{worst_step}**ï¼ˆ{worst_pp} ppï¼‰")
st.write({
    "viewâ†’cart å˜åŒ–(pp)": round(deltas["viewâ†’cart"], 2),
    "cartâ†’pay å˜åŒ–(pp)": round(deltas["cartâ†’pay"], 2),
    "viewâ†’pay å˜åŒ–(pp)": round(deltas["viewâ†’pay"], 2),
})

st.subheader("ğŸ“Œ å˜åŒ–æ‘˜è¦ï¼ˆç™¾åˆ†ç‚¹ ppï¼‰")
st.write({
    "viewâ†’cart å˜åŒ–(pp)": pp(prev.cr_view_to_cart, last.cr_view_to_cart),
    "cartâ†’pay å˜åŒ–(pp)": pp(prev.cr_cart_to_pay, last.cr_cart_to_pay),
    "viewâ†’pay å˜åŒ–(pp)": pp(prev.cr_view_to_pay, last.cr_view_to_pay),
})

# =========================
# LLM Interpretation (Auto report)
# =========================
model = REASONER_MODEL if deep_mode else CHAT_MODEL

report_prompt = f"""
ä½ æ˜¯äº’è”ç½‘äº§å“è¿è¥æ•°æ®åˆ†æåŠ©æ‰‹ã€‚ä¸‹é¢æ˜¯æ¼æ–—å¯¹æ¯”ç»“æœï¼ˆæŒ‰ç”¨æˆ·ï¼‰ï¼š
{df2.to_dict(orient="records")}

åŒæ—¶ï¼Œæˆ‘å·²ç»è®¡ç®—å‡ºå˜åŒ–ï¼ˆppï¼‰ï¼š
- viewâ†’cart: {deltas['viewâ†’cart']:.2f} pp
- cartâ†’pay: {deltas['cartâ†’pay']:.2f} pp
- viewâ†’pay: {deltas['viewâ†’pay']:.2f} pp
æœ€å¤§ä¸‹é™æ­¥éª¤ï¼š{worst_step}ï¼ˆ{worst_pp} ppï¼‰

è¯·è¾“å‡ºä¸€ä»½â€œè¿è¥æ´å¯Ÿæ—¥æŠ¥â€ï¼Œå¿…é¡»åŒ…å«ä»¥ä¸‹å°æ ‡é¢˜ï¼ˆç”¨ markdownï¼‰ï¼š
## ä¸€å¥è¯ç»“è®º
## å˜åŒ–æœ€å¤§çš„æ­¥éª¤ä¸å½±å“
## å¯èƒ½åŸå› ï¼ˆå‡è®¾ï¼‰
## ä¸‹ä¸€æ­¥æ’æŸ¥/æ‹†è§£å»ºè®®ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
è¦æ±‚ï¼š
- ä¸è¦åé—®ç”¨æˆ·ï¼Œä¸è¦è¦æ±‚è¡¥å……æ•°æ®
- æ‰€æœ‰åŸå› å¿…é¡»æ ‡æ˜æ˜¯å‡è®¾ï¼Œä¸è¦è£…ä½œå·²éªŒè¯
- å»ºè®®è¦å¯æ‰§è¡Œï¼ˆä¾‹å¦‚ï¼šæŒ‰ itemid/æ—¶é—´æ®µ/é«˜é¢‘ç”¨æˆ·æ‹†è§£ã€å¯¹æ¯”å¼‚å¸¸æ—¶æ®µç­‰ï¼‰
"""

with st.spinner("ç”Ÿæˆè¿è¥æ´å¯Ÿæ—¥æŠ¥ä¸­â€¦"):
    explanation = deepseek_chat(
        messages=[{"role": "user", "content": report_prompt}],
        model=model,
        temperature=0.3
    )

st.subheader("ğŸ§  è¿è¥æ´å¯Ÿæ—¥æŠ¥ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰")
st.markdown(explanation)
# =========================
# Export Report (Markdown)
# =========================
st.subheader("ğŸ“¥ å¯¼å‡ºæ—¥æŠ¥")

report_md = f"""# è¿è¥æ´å¯Ÿæ—¥æŠ¥ï¼ˆæ¼æ–—å¯¹æ¯”ï¼‰
...
{explanation}
"""

# ---------- æ–‡ä»¶åä¿¡æ¯ ----------
report_date = max_ts.strftime("%Y-%m-%d") if max_ts else "unknown_date"
funnel_tag = "ä¸¥æ ¼" if strict_mode else "å®½æ¾"
deep_tag = "_æ·±åº¦" if deep_mode else ""
file_name = f"è¿è¥æ´å¯Ÿæ—¥æŠ¥_{report_date}_{funnel_tag}{deep_tag}.md"

st.caption(f"å¯¼å‡ºæ–‡ä»¶åç¤ºä¾‹ï¼š{file_name}")

st.download_button(
    label="â¬‡ï¸ ä¸‹è½½ Markdown æ—¥æŠ¥ï¼ˆ.mdï¼‰",
    data=report_md.encode("utf-8"),
    file_name=file_name,
    mime="text/markdown"
)


# =========================
# Optional follow-up chat (collapsed)
# =========================
with st.expander("ğŸ’¬ å¯é€‰ï¼šç»§ç»­è¿½é—®ï¼ˆåŸºäºå½“å‰æ´å¯Ÿï¼‰", expanded=False):
    q = st.chat_input("ä¾‹å¦‚ï¼šä¸ºä»€ä¹ˆ viewâ†’cart ä¼šä½ï¼Ÿèƒ½æŒ‰ itemid/ç±»ç›®æ‹†ä¸€ä¸‹å—ï¼Ÿ")
    if q:
        follow_prompt = f"""
è¿™æ˜¯å½“å‰çš„å¯¹æ¯”æ¼æ–—ç»“æœï¼ˆæŒ‰ç”¨æˆ·ï¼‰ï¼š
{df2.to_dict(orient="records")}
 
ç”¨æˆ·è¿½é—®ï¼š{q}

è¯·åŸºäºå·²æœ‰ç»“æœå›ç­”ï¼›å¦‚æœéœ€è¦æ–°çš„ç»´åº¦/SQLï¼Œè¯·æ˜ç¡®è¯´æ˜éœ€è¦å“ªäº›å­—æ®µä»¥åŠä¸‹ä¸€æ­¥æ€ä¹ˆæŸ¥ã€‚
"""
        with st.spinner("ç”Ÿæˆå›ç­”ä¸­â€¦"):
            ans = deepseek_chat(
                messages=[{"role": "user", "content": follow_prompt}],
                model=model,
                temperature=0.3
            )
        st.markdown(ans)
