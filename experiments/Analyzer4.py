# =========================================================
# Analyzer1.py
# æ³›ç”¨å‹ Â· äº‹ä»¶æ¼æ–—è‡ªåŠ¨æ´å¯Ÿï¼ˆå«ç¤ºä¾‹æ•°æ®ï¼‰- ç¨³å®šç‰ˆ
# å…³é”®ä¿®å¤ï¼š
# 1) æ—¥æŠ¥æ”¹æˆæŒ‰é’®è§¦å‘ + ç¼“å­˜ï¼ˆè§£å†³â€œå¡ä½â€ï¼‰
# 2) CSV è¯»å–ç¼“å­˜ï¼ˆå¤§æ–‡ä»¶ä¸é‡å¤è¯»ï¼‰
# 3) prev/last æ’åºå›ºå®šï¼ˆé¿å…ç®—åï¼‰
# =========================================================

import os
import requests
import pandas as pd
import duckdb
import streamlit as st
from datetime import datetime, timedelta
import random

# =========================================================
# Page config
# =========================================================
st.set_page_config(page_title="äº‹ä»¶æ¼æ–—è‡ªåŠ¨æ´å¯Ÿ", layout="wide")

# =========================================================
# CSS ä¿®å¤æ»šåŠ¨æ¡
# =========================================================
st.markdown("""
<style>
html, body { overflow: auto !important; height: auto !important; }
[data-testid="stAppViewContainer"] { overflow: auto !important; }
[data-testid="stMain"], [data-testid="stSidebar"] {
  width: 100% !important;
  box-sizing: border-box !important;
}
</style>
""", unsafe_allow_html=True)

# =========================================================
# DeepSeek Config
# =========================================================
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
DEEPSEEK_BASE_URL = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
CHAT_MODEL = "deepseek-chat"
REASONER_MODEL = "deepseek-reasoner"

# =========================================================
# Utils
# =========================================================
def deepseek_chat(messages, model, temperature=0.3):
    if not DEEPSEEK_API_KEY:
        raise RuntimeError("Missing DEEPSEEK_API_KEY")
    headers = {
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {"model": model, "messages": messages, "temperature": temperature}
    r = requests.post(
        f"{DEEPSEEK_BASE_URL}/chat/completions",
        headers=headers,
        json=payload,
        timeout=120
    )
    r.raise_for_status()
    return r.json()["choices"][0]["message"]["content"]

def run_sql(con, q):
    return con.execute(q).df()

@st.cache_data(show_spinner=False)
def load_csv(file) -> pd.DataFrame:
    return pd.read_csv(file)

# =========================================================
# ç¤ºä¾‹æ•°æ®ç”Ÿæˆï¼ˆæ–¹å‘ B çš„å…³é”®ï¼‰
# =========================================================
def make_sample_data(n_users=200):
    base = datetime.now() - timedelta(days=14)
    rows = []
    for i in range(n_users):
        uid = f"user_{i}"
        t1 = base + timedelta(minutes=random.randint(0, 60*24*10))
        rows.append((uid, "page_view", int(t1.timestamp()*1000)))
        if random.random() < 0.6:
            t2 = t1 + timedelta(minutes=random.randint(1, 120))
            rows.append((uid, "click", int(t2.timestamp()*1000)))
            if random.random() < 0.4:
                t3 = t2 + timedelta(minutes=random.randint(1, 180))
                rows.append((uid, "purchase", int(t3.timestamp()*1000)))
    return pd.DataFrame(rows, columns=["user_id", "event", "timestamp"])

# =========================================================
# Sidebar
# =========================================================
st.sidebar.title("æ•°æ®æ¥æº")

use_sample = st.sidebar.checkbox("ğŸ§ª ä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼ˆæ— éœ€ä¸Šä¼ ï¼‰", value=False)
uploaded = st.sidebar.file_uploader("ğŸ“‚ æˆ–ä¸Šä¼  CSVï¼ˆuser / event / timestampï¼‰", type=["csv"])

deep_mode = st.sidebar.toggle("æ·±åº¦åˆ†æ", value=False)
strict_mode = st.sidebar.toggle("ä¸¥æ ¼æ¼æ–—", value=False)
window_days = st.sidebar.radio("å¯¹æ¯”å‘¨æœŸï¼ˆå¤©ï¼‰", [7, 14, 30], horizontal=True)

# =========================================================
# Main
# =========================================================
st.title("ğŸ“Š äº‹ä»¶æ¼æ–—è‡ªåŠ¨æ´å¯Ÿ")

st.markdown("""
**é€‚åˆï¼š** æœ‰äº‹ä»¶çº§æ•°æ®çš„äº§å“ / è¿è¥ / åˆ†æäººå‘˜  
**ä¸é€‚åˆï¼š** æ²¡æœ‰åŸ‹ç‚¹æˆ–ä¸æ¸…æ¥šäº‹ä»¶å«ä¹‰çš„ç”¨æˆ·
""")

# =========================================================
# Data load
# =========================================================
if use_sample:
    df = make_sample_data()
    st.info("å½“å‰ä½¿ç”¨ï¼šç¤ºä¾‹æ•°æ®ï¼ˆpage_view â†’ click â†’ purchaseï¼‰")
elif uploaded:
    df = load_csv(uploaded)
else:
    st.stop()

with st.expander("æ•°æ®é¢„è§ˆ", expanded=False):
    st.dataframe(df.head(20), use_container_width=True)

# =========================================================
# Column mapping
# =========================================================
cols = {c.lower(): c for c in df.columns}
uid_col = cols.get("user_id") or cols.get("visitorid")
evt_col = cols.get("event")
ts_col = cols.get("timestamp")

if not all([uid_col, evt_col, ts_col]):
    st.error("éœ€è¦åŒ…å« user_id / event / timestamp åˆ—")
    st.stop()

# =========================================================
# Event mapping
# =========================================================
st.sidebar.subheader("æ¼æ–—äº‹ä»¶æ˜ å°„")
events = sorted(df[evt_col].astype(str).unique().tolist())

s1 = st.sidebar.selectbox("Step 1", events, index=0)
s2 = st.sidebar.selectbox("Step 2", events, index=min(1, len(events)-1))
s3 = st.sidebar.selectbox("Step 3", events, index=min(2, len(events)-1))

# é˜²æ­¢å•å¼•å·å¯¼è‡´ SQL æŠ¥é”™
s1, s2, s3 = [x.replace("'", "''") for x in (s1, s2, s3)]

# =========================================================
# DuckDB
# =========================================================
con = duckdb.connect(":memory:")
con.register("events", df)

max_ts = con.execute(f"SELECT MAX(to_timestamp({ts_col}/1000)) FROM events").fetchone()[0]
st.caption(f"æ—¶é—´åŸºå‡†ï¼š{max_ts}ï¼ˆlast_{window_days}d vs prev_{window_days}dï¼‰")

# =========================================================
# Funnel SQLï¼ˆå®½æ¾/ä¸¥æ ¼ï¼‰
# =========================================================
def funnel_sql(strict=False):
    n = int(window_days)
    if not strict:
        return f"""
WITH b AS (SELECT MAX(to_timestamp({ts_col}/1000)) m FROM events),
c AS (
  SELECT {uid_col} u, {evt_col} e, to_timestamp({ts_col}/1000) t,
  CASE
    WHEN t >= (SELECT m FROM b) - INTERVAL {n} DAY THEN 'last'
    WHEN t >= (SELECT m FROM b) - INTERVAL {2*n} DAY
     AND t <  (SELECT m FROM b) - INTERVAL {n} DAY THEN 'prev'
  END p
  FROM events
  WHERE e IN ('{s1}','{s2}','{s3}')
)
SELECT p,
  COUNT(DISTINCT CASE WHEN e='{s1}' THEN u END) s1,
  COUNT(DISTINCT CASE WHEN e='{s2}' THEN u END) s2,
  COUNT(DISTINCT CASE WHEN e='{s3}' THEN u END) s3
FROM c
WHERE p IS NOT NULL
GROUP BY 1;
"""
    else:
        return f"""
WITH b AS (SELECT MAX(to_timestamp({ts_col}/1000)) m FROM events),
c AS (
  SELECT {uid_col} u, {evt_col} e, to_timestamp({ts_col}/1000) t,
  CASE
    WHEN t >= (SELECT m FROM b) - INTERVAL {n} DAY THEN 'last'
    WHEN t >= (SELECT m FROM b) - INTERVAL {2*n} DAY
     AND t <  (SELECT m FROM b) - INTERVAL {n} DAY THEN 'prev'
  END p
  FROM events
  WHERE e IN ('{s1}','{s2}','{s3}')
),
u AS (
  SELECT u, p,
    MIN(CASE WHEN e='{s1}' THEN t END) t1,
    MIN(CASE WHEN e='{s2}' THEN t END) t2,
    MIN(CASE WHEN e='{s3}' THEN t END) t3
  FROM c
  WHERE p IS NOT NULL
  GROUP BY 1,2
)
SELECT p,
  COUNT(*) FILTER (WHERE t1 IS NOT NULL) s1,
  COUNT(*) FILTER (WHERE t1 IS NOT NULL AND t2 >= t1) s2,
  COUNT(*) FILTER (WHERE t1 IS NOT NULL AND t2 >= t1 AND t3 >= t2) s3
FROM u
GROUP BY 1;
"""

res = run_sql(con, funnel_sql(strict_mode))

# å›ºå®šé¡ºåºï¼šprev åœ¨å‰ï¼Œlast åœ¨åï¼ˆé¿å…ç®—åï¼‰
res["__o"] = res["p"].map({"prev": 0, "last": 1})
res = res.sort_values("__o").drop(columns="__o").reset_index(drop=True)

st.subheader("ğŸ“ˆ æ¼æ–—å¯¹æ¯”ç»“æœ")
st.dataframe(res, use_container_width=True)

# =========================================================
# Auto Insight
# =========================================================
if res.shape[0] < 2:
    st.warning("æ²¡æœ‰å¾—åˆ° prev/last ä¸¤æœŸæ•°æ®ï¼Œå¯èƒ½æ˜¯æ•°æ®æ—¶é—´è·¨åº¦ä¸è¶³æˆ–äº‹ä»¶è¿‡å°‘ã€‚")
    st.stop()

prev, last = res.iloc[0], res.iloc[1]

def safe_rate(num, den):
    return (num / den) if den else 0.0

prev_r12 = safe_rate(prev.s2, prev.s1)
last_r12 = safe_rate(last.s2, last.s1)
prev_r23 = safe_rate(prev.s3, prev.s2)
last_r23 = safe_rate(last.s3, last.s2)

d12 = (last_r12 - prev_r12) * 100
d23 = (last_r23 - prev_r23) * 100

worst = min([("Step1â†’Step2", d12), ("Step2â†’Step3", d23)], key=lambda x: x[1])

st.subheader("ğŸš¨ è‡ªåŠ¨æ´å¯Ÿ")
st.markdown(
    f"- Step1ï¼ˆ{s1}ï¼‰ç”¨æˆ·ï¼š**{int(last.s1):,}**ï¼ˆÎ” {int(last.s1 - prev.s1):,}ï¼‰\n"
    f"- Step2ï¼ˆ{s2}ï¼‰ç”¨æˆ·ï¼š**{int(last.s2):,}**ï¼ˆÎ” {int(last.s2 - prev.s2):,}ï¼‰\n"
    f"- Step3ï¼ˆ{s3}ï¼‰ç”¨æˆ·ï¼š**{int(last.s3):,}**ï¼ˆÎ” {int(last.s3 - prev.s3):,}ï¼‰"
)
st.markdown(f"**æœ€å¤§ä¸‹é™æ­¥éª¤**ï¼š{worst[0]}ï¼ˆ{worst[1]:.2f} ppï¼‰")

# =========================================================
# LLM Report (æŒ‰é’®è§¦å‘ + ç¼“å­˜) â€”â€” è§£å†³â€œå¡ä½â€
# =========================================================
model = REASONER_MODEL if deep_mode else CHAT_MODEL

# æŠ¥å‘Šç¼“å­˜ï¼ˆç›¸åŒå‚æ•°ä¸é‡å¤è°ƒæ¨¡å‹ï¼‰
if "report_cache" not in st.session_state:
    st.session_state.report_cache = {}

report_key = f"{window_days}|{strict_mode}|{deep_mode}|{s1}|{s2}|{s3}|{int(last.s1)}|{int(last.s2)}|{int(last.s3)}"

st.subheader("ğŸ§  è¿è¥æ´å¯Ÿæ—¥æŠ¥")

col1, col2 = st.columns([1, 3])
with col1:
    gen = st.button("ç”Ÿæˆ/åˆ·æ–°æ—¥æŠ¥", type="primary", use_container_width=True)
with col2:
    st.caption("åˆ‡æ¢å‘¨æœŸ/äº‹ä»¶ä¼šå¯¼è‡´é¡µé¢é‡è·‘ï¼›æ—¥æŠ¥å»ºè®®æ‰‹åŠ¨ç”Ÿæˆï¼Œé¿å…é¢‘ç¹è°ƒç”¨æ¨¡å‹ã€‚")

# ç‚¹å‡»æŒ‰é’®æ‰è°ƒç”¨ LLM
if gen:
    prompt = f"""
è¿™æ˜¯ä¸€ä¸ª 3 æ­¥äº‹ä»¶æ¼æ–—å¯¹æ¯”ç»“æœï¼š
{res.to_dict(orient="records")}

Step1={s1}, Step2={s2}, Step3={s3}
æœ¬æœŸï¼ˆlastï¼‰è½¬åŒ–ï¼š
- Step1â†’Step2: {last_r12*100:.2f}%
- Step2â†’Step3: {last_r23*100:.2f}%

å˜åŒ–ï¼ˆppï¼‰ï¼š
- Step1â†’Step2: {d12:.2f}pp
- Step2â†’Step3: {d23:.2f}pp
æœ€å¤§ä¸‹é™æ­¥éª¤ï¼š{worst[0]}ï¼ˆ{worst[1]:.2f}ppï¼‰

è¯·ç”Ÿæˆä¸€ä»½è¿è¥æ´å¯Ÿæ—¥æŠ¥ï¼ˆMarkdownï¼‰ï¼Œå¿…é¡»åŒ…å«ï¼š
## ä¸€å¥è¯ç»“è®º
## å˜åŒ–æœ€å¤§çš„æ­¥éª¤ä¸å½±å“
## å¯èƒ½åŸå› ï¼ˆå‡è®¾ï¼‰
## ä¸‹ä¸€æ­¥æ’æŸ¥å»ºè®®ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
è¦æ±‚ï¼šä¸è¦åé—®ç”¨æˆ·ï¼›åŸå› å¿…é¡»æ ‡æ³¨â€œå‡è®¾â€ï¼›å»ºè®®è¦å¯æ‰§è¡Œã€‚
"""
    try:
        with st.spinner("ç”Ÿæˆæ—¥æŠ¥ä¸­â€¦ï¼ˆæ·±åº¦åˆ†æä¼šæ›´æ…¢ï¼‰"):
            report = deepseek_chat([{"role": "user", "content": prompt}], model=model)
        st.session_state.report_cache[report_key] = report
    except Exception as e:
        st.error("æ—¥æŠ¥ç”Ÿæˆå¤±è´¥ï¼ˆå¯èƒ½æ˜¯ç½‘ç»œ/é™æµ/Key/è¶…æ—¶ï¼‰ã€‚")
        st.code(str(e))

# å±•ç¤ºç¼“å­˜å†…å®¹ï¼ˆæœ‰å°±å±•ç¤ºï¼Œæ²¡æœ‰å°±æç¤ºï¼‰
report = st.session_state.report_cache.get(report_key)
if report:
    st.markdown(report)
else:
    st.info("ç‚¹å‡»ä¸Šé¢çš„ã€Œç”Ÿæˆ/åˆ·æ–°æ—¥æŠ¥ã€æ¥ç”Ÿæˆæ´å¯Ÿæ—¥æŠ¥ã€‚")

# =========================================================
# Export
# =========================================================
st.subheader("ğŸ“¥ å¯¼å‡º")
md = f"# äº‹ä»¶æ¼æ–—æ´å¯Ÿæ—¥æŠ¥\n\n- Step1: {s1}\n- Step2: {s2}\n- Step3: {s3}\n- å‘¨æœŸ: {window_days}d\n- ä¸¥æ ¼æ¼æ–—: {strict_mode}\n- æ·±åº¦åˆ†æ: {deep_mode}\n\n---\n\n{report or 'ï¼ˆå°šæœªç”Ÿæˆæ—¥æŠ¥ï¼Œè¯·å…ˆç‚¹å‡»â€œç”Ÿæˆ/åˆ·æ–°æ—¥æŠ¥â€ï¼‰'}"
fname = f"äº‹ä»¶æ¼æ–—æ´å¯Ÿ_{window_days}d.md"
st.download_button("â¬‡ï¸ ä¸‹è½½ Markdown æ—¥æŠ¥", md.encode("utf-8"), fname)
