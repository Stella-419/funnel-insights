# =========================
# Analyzer1.py  (Auto Insights + Multi-window + Export)
# =========================

import os
import re
import json
import requests
import pandas as pd
import duckdb
import streamlit as st

# =========================
# Page config
# =========================
st.set_page_config(
    page_title="è¿è¥æ¼æ–—æ´å¯Ÿï¼ˆRetailRocketï¼‰",
    layout="wide"
)

# =========================
# ğŸ”§ å¼ºåŠ›å…œåº•ï¼šä¿®å¤æ»šåŠ¨æ¡é—®é¢˜
# =========================
st.markdown("""
<style>
html, body {
  overflow: auto !important;
  height: auto !important;
}
[data-testid="stAppViewContainer"] {
  overflow: auto !important;
}
/* é˜²æ­¢ fixed + 100vw è¦†ç›–æ»šåŠ¨æ¡ */
[data-testid="stChatInput"],
[data-testid="stHeader"],
[data-testid="stToolbar"],
[data-testid="stMain"],
[data-testid="stSidebar"] {
  width: 100% !important;
  box-sizing: border-box !important;
}
</style>
""", unsafe_allow_html=True)

# =========================
# DeepSeek Config
# =========================
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
DEEPSEEK_BASE_URL = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
CHAT_MODEL = "deepseek-chat"
REASONER_MODEL = "deepseek-reasoner"

# =========================
# Utils
# =========================
def deepseek_chat(messages, model, json_mode=False, temperature=0.3):
    if not DEEPSEEK_API_KEY:
        raise RuntimeError("Missing DEEPSEEK_API_KEY. Please set environment variable DEEPSEEK_API_KEY.")

    headers = {
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": model,
        "messages": messages,
        "temperature": temperature
    }
    if json_mode:
        payload["response_format"] = {"type": "json_object"}

    r = requests.post(
        f"{DEEPSEEK_BASE_URL}/chat/completions",
        headers=headers,
        json=payload,
        timeout=120
    )
    r.raise_for_status()
    return r.json()["choices"][0]["message"]["content"]


def run_sql(con, sql_query, max_rows=200):
    cleaned = sql_query.strip().rstrip(";")
    lower = cleaned.lower()
    if not (lower.startswith("select") or lower.startswith("with")):
        raise ValueError("Only SELECT/WITH allowed")

    limited_sql = f"""
    SELECT *
    FROM (
        {cleaned}
    ) t
    LIMIT {int(max_rows)}
    """
    return con.execute(limited_sql).df()


def get_alert_threshold_pp(window_days: int) -> float:
    """
    å‘¨æœŸè¶Šé•¿ï¼Œé˜ˆå€¼è¶Šä¸¥æ ¼ï¼ˆæ›´å®¹æ˜“æ•æ‰å°å˜åŒ–ï¼‰
    ä½ å¯ä»¥æŒ‰ä¸šåŠ¡è°ƒæ•´ã€‚
    """
    if window_days >= 30:
        return 0.15
    if window_days >= 14:
        return 0.20
    return 0.30


def alert_level(delta_pp: float, threshold_pp: float) -> str:
    """
    delta_pp: å˜åŒ–ï¼ˆppï¼‰ï¼Œè´Ÿæ•°è¡¨ç¤ºå˜å·®
    """
    if delta_pp <= -threshold_pp:
        return "ğŸ”´ å¼‚å¸¸ä¸‹é™"
    if delta_pp <= -threshold_pp / 2:
        return "ğŸŸ  è½»å¾®ä¸‹é™"
    if delta_pp >= threshold_pp:
        return "ğŸŸ¢ æ˜æ˜¾æ”¹å–„"
    return "âšª åŸºæœ¬ç¨³å®š"


def find_biggest_drop_pp(prev_row, last_row):
    """Return worst step and deltas in percentage points (pp). Negative means worse."""
    deltas = {
        "viewâ†’cart": (float(last_row["cr_view_to_cart"]) - float(prev_row["cr_view_to_cart"])) * 100.0,
        "cartâ†’pay":  (float(last_row["cr_cart_to_pay"])  - float(prev_row["cr_cart_to_pay"]))  * 100.0,
        "viewâ†’pay":  (float(last_row["cr_view_to_pay"])  - float(prev_row["cr_view_to_pay"]))  * 100.0,
    }
    worst_step = min(deltas, key=deltas.get)  # most negative
    return worst_step, round(deltas[worst_step], 2), deltas


# =========================
# Funnel SQL Templates (data-relative last_Nd vs prev_Nd)
# =========================
def compare_funnel_sql_loose(ts: str, uid: str, evt: str, window_days: int) -> str:
    n = int(window_days)
    return f"""
WITH bounds AS (
  SELECT MAX(to_timestamp({ts}/1000)) AS max_ts
  FROM events
),
base AS (
  SELECT
    {uid} AS user_id,
    {evt} AS event,
    to_timestamp({ts} / 1000) AS ts,
    CASE
      WHEN to_timestamp({ts} / 1000) >= (SELECT max_ts FROM bounds) - INTERVAL {n} DAY THEN 'last_{n}d'
      WHEN to_timestamp({ts} / 1000) >= (SELECT max_ts FROM bounds) - INTERVAL {2*n} DAY
       AND to_timestamp({ts} / 1000) <  (SELECT max_ts FROM bounds) - INTERVAL {n} DAY THEN 'prev_{n}d'
      ELSE NULL
    END AS period
  FROM events
  WHERE {evt} IN ('view','addtocart','transaction')
),
agg AS (
  SELECT
    period,
    COUNT(DISTINCT CASE WHEN event='view' THEN user_id END)        AS view_users,
    COUNT(DISTINCT CASE WHEN event='addtocart' THEN user_id END)   AS cart_users,
    COUNT(DISTINCT CASE WHEN event='transaction' THEN user_id END) AS pay_users
  FROM base
  WHERE period IS NOT NULL
  GROUP BY 1
)
SELECT
  period,
  view_users, cart_users, pay_users,
  cart_users * 1.0 / NULLIF(view_users,0) AS cr_view_to_cart,
  pay_users  * 1.0 / NULLIF(cart_users,0) AS cr_cart_to_pay,
  pay_users  * 1.0 / NULLIF(view_users,0) AS cr_view_to_pay
FROM agg
ORDER BY CASE period WHEN 'prev_{n}d' THEN 1 ELSE 2 END
"""


def compare_funnel_sql_strict(ts: str, uid: str, evt: str, window_days: int) -> str:
    n = int(window_days)
    return f"""
WITH bounds AS (
  SELECT MAX(to_timestamp({ts}/1000)) AS max_ts
  FROM events
),
filtered AS (
  SELECT
    {uid} AS user_id,
    {evt} AS event,
    to_timestamp({ts} / 1000) AS ts,
    CASE
      WHEN to_timestamp({ts} / 1000) >= (SELECT max_ts FROM bounds) - INTERVAL {n} DAY THEN 'last_{n}d'
      WHEN to_timestamp({ts} / 1000) >= (SELECT max_ts FROM bounds) - INTERVAL {2*n} DAY
       AND to_timestamp({ts} / 1000) <  (SELECT max_ts FROM bounds) - INTERVAL {n} DAY THEN 'prev_{n}d'
      ELSE NULL
    END AS period
  FROM events
  WHERE {evt} IN ('view','addtocart','transaction')
),
u AS (
  SELECT
    user_id,
    period,
    MIN(CASE WHEN event='view'        THEN ts END) AS t_view,
    MIN(CASE WHEN event='addtocart'   THEN ts END) AS t_cart,
    MIN(CASE WHEN event='transaction' THEN ts END) AS t_pay
  FROM filtered
  WHERE period IS NOT NULL
  GROUP BY 1,2
),
agg AS (
  SELECT
    period,
    COUNT(*) FILTER (WHERE t_view IS NOT NULL) AS view_users,
    COUNT(*) FILTER (WHERE t_view IS NOT NULL AND t_cart IS NOT NULL AND t_cart >= t_view) AS cart_users,
    COUNT(*) FILTER (
      WHERE t_view IS NOT NULL AND t_cart IS NOT NULL AND t_pay IS NOT NULL
        AND t_cart >= t_view AND t_pay >= t_cart
    ) AS pay_users
  FROM u
  GROUP BY 1
)
SELECT
  period,
  view_users, cart_users, pay_users,
  cart_users * 1.0 / NULLIF(view_users,0) AS cr_view_to_cart,
  pay_users  * 1.0 / NULLIF(cart_users,0) AS cr_cart_to_pay,
  pay_users  * 1.0 / NULLIF(view_users,0) AS cr_view_to_pay
FROM agg
ORDER BY CASE period WHEN 'prev_{n}d' THEN 1 ELSE 2 END
"""


# =========================
# UI - Sidebar
# =========================
st.sidebar.title("è®¾ç½®")
deep_mode = st.sidebar.toggle("æ·±åº¦åˆ†æï¼ˆreasonerï¼‰", value=False, help="å¼€å¯åæ¨ç†æ›´æ·±ä½†æ›´æ…¢")
strict_mode = st.sidebar.toggle("ä¸¥æ ¼æ¼æ–—ï¼ˆé¡ºåºï¼‰", value=False, help="ä¸¥æ ¼ï¼šå¿…é¡» viewâ†’addtocartâ†’transaction é¡ºåºæ»¡è¶³")
compare_mode = st.sidebar.toggle("å¯¹æ¯”ï¼ˆæœ¬æœŸ vs ä¸ŠæœŸï¼‰", value=True, help="last_Nd vs prev_Ndï¼ŒåŸºäºæ•°æ®æœ€å¤§æ—¶é—´")
window_days = st.sidebar.radio("å¯¹æ¯”å‘¨æœŸé•¿åº¦", options=[7, 14, 30], index=0, horizontal=True)
max_rows = st.sidebar.slider("SQL è¿”å›æœ€å¤§è¡Œæ•°", 50, 500, 200, 50)
uploaded = st.sidebar.file_uploader("ä¸Šä¼  events.csv", type=["csv"])

# =========================
# Main
# =========================
st.title("ğŸ“Š è¿è¥æ¼æ–—æ´å¯Ÿï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰")

if not uploaded:
    st.info("è¯·åœ¨å·¦ä¾§ä¸Šä¼  RetailRocket çš„ events.csv")
    st.stop()

df = pd.read_csv(uploaded)

with st.expander("æ•°æ®é¢„è§ˆ", expanded=False):
    st.dataframe(df.head(30), use_container_width=True)

# è‡ªåŠ¨è¯†åˆ«åˆ—å
cols = {c.lower(): c for c in df.columns}
ts_col = cols.get("timestamp")
uid_col = cols.get("visitorid")
evt_col = cols.get("event")

if not all([ts_col, uid_col, evt_col]):
    st.error("æœªè¯†åˆ«åˆ° timestamp / visitorid / event åˆ—ã€‚è¯·ç¡®è®¤ CSV åˆ—åã€‚")
    st.stop()

# DuckDB
con = duckdb.connect(database=":memory:")
con.register("events_df", df)
con.execute("CREATE TABLE events AS SELECT * FROM events_df")

# æ•°æ®æœ€å¤§æ—¶é—´ï¼ˆå‘Šè¯‰ç”¨æˆ·â€œæœ€è¿‘Nå¤©â€æ˜¯ç›¸å¯¹æ•°æ®æ—¶é—´ï¼‰
max_ts = con.execute(f"SELECT MAX(to_timestamp({ts_col}/1000)) FROM events").fetchone()[0]
st.caption(
    f"æ—¶é—´çª—å£è¯´æ˜ï¼šä»¥æ•°æ®æœ€æ–°æ—¶é—´ **{max_ts}** ä¸ºåŸºå‡†ï¼Œè®¡ç®— last_{window_days}dï¼ˆæœ€è¿‘{window_days}å¤©ï¼‰"
    f" ä¸ prev_{window_days}dï¼ˆå‰{window_days}å¤©ï¼‰ã€‚"
)

if not compare_mode:
    st.warning("å½“å‰ç‰ˆæœ¬ä¸ºâ€œè‡ªåŠ¨æ´å¯Ÿâ€æ¨¡å¼ï¼Œå»ºè®®å¼€å¯å¯¹æ¯”æ¨¡å¼ï¼ˆæœ¬æœŸ vs ä¸ŠæœŸï¼‰ã€‚")
    st.stop()

# =========================
# Run funnel (Auto)
# =========================
sql_query = (
    compare_funnel_sql_strict(ts_col, uid_col, evt_col, window_days)
    if strict_mode else
    compare_funnel_sql_loose(ts_col, uid_col, evt_col, window_days)
)

try:
    result_df = run_sql(con, sql_query, max_rows=max_rows)
except Exception as e:
    st.error("SQL æ‰§è¡Œå¤±è´¥ï¼ˆå¯èƒ½æ˜¯åˆ—å/æ•°æ®ç±»å‹é—®é¢˜ï¼‰ã€‚")
    st.code(sql_query, language="sql")
    st.code(str(e))
    st.stop()

st.subheader("ğŸ“ˆ å¯¹æ¯”æ¼æ–—ç»“æœï¼ˆæŒ‰ç”¨æˆ·ï¼‰")
st.dataframe(result_df, use_container_width=True)

# =========================
# Auto Insight Cards
# =========================
prev_tag = f"prev_{window_days}d"
last_tag = f"last_{window_days}d"
order = {prev_tag: 0, last_tag: 1}

df2 = result_df.copy()
if "period" not in df2.columns or df2.shape[0] < 2:
    st.warning("æœªå¾—åˆ°æœ¬æœŸ/ä¸ŠæœŸä¸¤æœŸç»“æœï¼Œè¯·æ£€æŸ¥æ•°æ®æˆ– SQLã€‚")
    st.stop()

df2["__o"] = df2["period"].map(order)
df2 = df2.sort_values("__o").drop(columns="__o")

prev = df2[df2["period"] == prev_tag].iloc[0]
last = df2[df2["period"] == last_tag].iloc[0]

worst_step, worst_pp, deltas = find_biggest_drop_pp(prev, last)

threshold_pp = get_alert_threshold_pp(window_days)
levels = {k: alert_level(v, threshold_pp) for k, v in deltas.items()}

st.subheader("ğŸš¨ è‡ªåŠ¨æ´å¯Ÿï¼ˆæœ¬æœŸ vs ä¸ŠæœŸï¼‰")

c1, c2, c3 = st.columns(3)
with c1:
    st.metric("æµè§ˆç”¨æˆ·ï¼ˆviewï¼‰", int(last["view_users"]), int(last["view_users"] - prev["view_users"]))
with c2:
    st.metric("åŠ è´­ç”¨æˆ·ï¼ˆaddtocartï¼‰", int(last["cart_users"]), int(last["cart_users"] - prev["cart_users"]))
with c3:
    st.metric("æˆäº¤ç”¨æˆ·ï¼ˆtransactionï¼‰", int(last["pay_users"]), int(last["pay_users"] - prev["pay_users"]))

st.markdown(f"**æœ€å¤§ä¸‹é™æ­¥éª¤**ï¼š**{worst_step}**ï¼ˆ{worst_pp} ppï¼‰")
st.caption(f"é¢„è­¦é˜ˆå€¼ï¼š{threshold_pp:.2f} ppï¼ˆå‘¨æœŸè¶Šé•¿é˜ˆå€¼è¶Šä¸¥æ ¼ï¼‰")

st.write({
    "viewâ†’cart å˜åŒ–(pp)": f"{deltas['viewâ†’cart']:.2f} pp  {levels['viewâ†’cart']}",
    "cartâ†’pay å˜åŒ–(pp)":  f"{deltas['cartâ†’pay']:.2f} pp  {levels['cartâ†’pay']}",
    "viewâ†’pay å˜åŒ–(pp)":  f"{deltas['viewâ†’pay']:.2f} pp  {levels['viewâ†’pay']}",
})

# =========================
# LLM Interpretation (Auto report)
# =========================
model = REASONER_MODEL if deep_mode else CHAT_MODEL

report_prompt = f"""
ä½ æ˜¯äº’è”ç½‘äº§å“è¿è¥æ•°æ®åˆ†æåŠ©æ‰‹ã€‚ä¸‹é¢æ˜¯æ¼æ–—å¯¹æ¯”ç»“æœï¼ˆæŒ‰ç”¨æˆ·ï¼‰ï¼š
{df2.to_dict(orient="records")}

å˜åŒ–ï¼ˆppï¼‰ï¼š
- viewâ†’cart: {deltas['viewâ†’cart']:.2f} ppï¼ˆ{levels['viewâ†’cart']}ï¼‰
- cartâ†’pay: {deltas['cartâ†’pay']:.2f} ppï¼ˆ{levels['cartâ†’pay']}ï¼‰
- viewâ†’pay: {deltas['viewâ†’pay']:.2f} ppï¼ˆ{levels['viewâ†’pay']}ï¼‰
æœ€å¤§ä¸‹é™æ­¥éª¤ï¼š{worst_step}ï¼ˆ{worst_pp} ppï¼‰
æ—¶é—´çª—å£ï¼šlast_{window_days}d vs prev_{window_days}dï¼ˆåŸºäºæ•°æ®æœ€å¤§æ—¶é—´ {max_ts}ï¼‰
æ¼æ–—æ¨¡å¼ï¼š{"ä¸¥æ ¼ï¼ˆé¡ºåºï¼‰" if strict_mode else "å®½æ¾ï¼ˆå‘ç”Ÿè¿‡å³ç®—ï¼‰"}

è¯·è¾“å‡ºä¸€ä»½â€œè¿è¥æ´å¯Ÿæ—¥æŠ¥â€ï¼Œå¿…é¡»åŒ…å«ä»¥ä¸‹å°æ ‡é¢˜ï¼ˆmarkdownï¼‰ï¼š
## ä¸€å¥è¯ç»“è®º
## å˜åŒ–æœ€å¤§çš„æ­¥éª¤ä¸å½±å“
## å¯èƒ½åŸå› ï¼ˆå‡è®¾ï¼‰
## ä¸‹ä¸€æ­¥æ’æŸ¥/æ‹†è§£å»ºè®®ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
è¦æ±‚ï¼š
- ä¸è¦åé—®ç”¨æˆ·ï¼Œä¸è¦è¦æ±‚è¡¥å……æ•°æ®
- åŸå› å¿…é¡»æ ‡æ˜æ˜¯å‡è®¾ï¼Œä¸è¦è£…ä½œå·²éªŒè¯
- å»ºè®®è¦å¯æ‰§è¡Œï¼ˆä¾‹å¦‚ï¼šæŒ‰ itemid/æ—¶é—´æ®µ/é«˜é¢‘ç”¨æˆ·/æ–°è€ç”¨æˆ·æ‹†è§£ã€å¯¹æ¯”å¼‚å¸¸æ—¶æ®µç­‰ï¼‰
"""

with st.spinner("ç”Ÿæˆè¿è¥æ´å¯Ÿæ—¥æŠ¥ä¸­â€¦"):
    explanation = deepseek_chat(
        messages=[{"role": "user", "content": report_prompt}],
        model=model,
        temperature=0.3
    )

st.subheader("ğŸ§  è¿è¥æ´å¯Ÿæ—¥æŠ¥ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰")
st.markdown(explanation)

# =========================
# ğŸ“¥ Export Report (Markdown)
# =========================
st.subheader("ğŸ“¥ ä¸€é”®å¯¼å‡ºæ—¥æŠ¥ï¼ˆMarkdownï¼‰")

report_md = f"""# è¿è¥æ´å¯Ÿæ—¥æŠ¥ï¼ˆæ¼æ–—å¯¹æ¯”ï¼‰

**æ•°æ®çª—å£ï¼ˆä»¥æ•°æ®æœ€æ–°æ—¶é—´ä¸ºåŸºå‡†ï¼‰**ï¼š{max_ts}  
**å¯¹æ¯”å‘¨æœŸ**ï¼šlast_{window_days}d vs prev_{window_days}d  
**æ¼æ–—æ¨¡å¼**ï¼š{"ä¸¥æ ¼ï¼ˆé¡ºåºï¼‰" if strict_mode else "å®½æ¾ï¼ˆå‘ç”Ÿè¿‡å³ç®—ï¼‰"}  
**æ·±åº¦åˆ†æ**ï¼š{"æ˜¯" if deep_mode else "å¦"}

## æ ¸å¿ƒæŒ‡æ ‡ï¼ˆ{last_tag}ï¼‰
- æµè§ˆç”¨æˆ·ï¼ˆviewï¼‰ï¼š{int(last["view_users"]):,}
- åŠ è´­ç”¨æˆ·ï¼ˆaddtocartï¼‰ï¼š{int(last["cart_users"]):,}
- æˆäº¤ç”¨æˆ·ï¼ˆtransactionï¼‰ï¼š{int(last["pay_users"]):,}
- viewâ†’cartï¼š{float(last["cr_view_to_cart"])*100:.2f}%
- cartâ†’payï¼š{float(last["cr_cart_to_pay"])*100:.2f}%
- viewâ†’payï¼š{float(last["cr_view_to_pay"])*100:.2f}%

## å˜åŒ–æ‘˜è¦ï¼ˆ{last_tag} - {prev_tag}ï¼Œppï¼›é˜ˆå€¼ {threshold_pp:.2f} ppï¼‰
- viewâ†’cartï¼š{deltas["viewâ†’cart"]:.2f} ppï¼ˆ{levels["viewâ†’cart"]}ï¼‰
- cartâ†’payï¼š{deltas["cartâ†’pay"]:.2f} ppï¼ˆ{levels["cartâ†’pay"]}ï¼‰
- viewâ†’payï¼š{deltas["viewâ†’pay"]:.2f} ppï¼ˆ{levels["viewâ†’pay"]}ï¼‰
- **æœ€å¤§ä¸‹é™æ­¥éª¤**ï¼š**{worst_step}**ï¼ˆ{worst_pp} ppï¼‰

---

{explanation}
"""

report_date = max_ts.strftime("%Y-%m-%d") if max_ts else "unknown_date"
funnel_tag = "ä¸¥æ ¼" if strict_mode else "å®½æ¾"
deep_tag = "_æ·±åº¦" if deep_mode else ""
file_name = f"è¿è¥æ´å¯Ÿæ—¥æŠ¥_{report_date}_{window_days}d_{funnel_tag}{deep_tag}.md"

st.caption(f"å¯¼å‡ºæ–‡ä»¶åï¼š{file_name}")

st.download_button(
    label="â¬‡ï¸ ä¸‹è½½ Markdown æ—¥æŠ¥ï¼ˆ.mdï¼‰",
    data=report_md.encode("utf-8"),
    file_name=file_name,
    mime="text/markdown"
)

# =========================
# Optional follow-up chat (collapsed)
# =========================
with st.expander("ğŸ’¬ å¯é€‰ï¼šç»§ç»­è¿½é—®ï¼ˆåŸºäºå½“å‰æ´å¯Ÿï¼‰", expanded=False):
    q = st.chat_input("ä¾‹å¦‚ï¼šä¸ºä»€ä¹ˆ viewâ†’cart ä¼šä½ï¼Ÿèƒ½æŒ‰ itemid/ç±»ç›®æ‹†ä¸€ä¸‹å—ï¼Ÿ")
    if q:
        follow_prompt = f"""
è¿™æ˜¯å½“å‰çš„å¯¹æ¯”æ¼æ–—ç»“æœï¼ˆæŒ‰ç”¨æˆ·ï¼‰ï¼š
{df2.to_dict(orient="records")}

ç”¨æˆ·è¿½é—®ï¼š{q}

è¯·åŸºäºå·²æœ‰ç»“æœå›ç­”ï¼›å¦‚æœéœ€è¦æ–°çš„ç»´åº¦/SQLï¼Œè¯·æ˜ç¡®è¯´æ˜éœ€è¦å“ªäº›å­—æ®µä»¥åŠä¸‹ä¸€æ­¥æ€ä¹ˆæŸ¥ã€‚
"""
        with st.spinner("ç”Ÿæˆå›ç­”ä¸­â€¦"):
            ans = deepseek_chat(
                messages=[{"role": "user", "content": follow_prompt}],
                model=model,
                temperature=0.3
            )
        st.markdown(ans)
