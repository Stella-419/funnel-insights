# app/Analyzer.py
# UI å…¥å£å±‚ï¼šåªè´Ÿè´£ Streamlit äº¤äº’ + è°ƒç”¨ core é€»è¾‘

import sys
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))


import os
import requests
import pandas as pd
import duckdb
import streamlit as st

from app.core import (
    make_sample_data,
    infer_breakdown_candidates,
    classify_dim,
    funnel_sql_nstep,
    compute_rates_and_deltas,
    find_worst_delta,
    pretty_step_label,
    threshold_pp,
    level,
    emoji_from_level,
    build_hint,
    fmt_int,
    pp,
    pct,
    build_export_markdown,
)

# =========================================================
# Streamlit config
# =========================================================
st.set_page_config(page_title="äº‹ä»¶æ¼æ–—æ´å¯ŸåŠ©æ‰‹", layout="wide")

st.markdown(
    """
<style>
html, body { overflow: auto !important; height: auto !important; }
[data-testid="stAppViewContainer"] { overflow: auto !important; }
[data-testid="stMain"], [data-testid="stSidebar"] { width: 100% !important; box-sizing: border-box !important; }
[data-testid="stMetricValue"] { font-size: 2.2rem !important; }
</style>
""",
    unsafe_allow_html=True,
)

# =========================================================
# DeepSeek config (UI/infra å±‚)
# =========================================================
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
DEEPSEEK_BASE_URL = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
CHAT_MODEL = "deepseek-chat"
REASONER_MODEL = "deepseek-reasoner"


def deepseek_chat(messages, model, temperature=0.3):
    if not DEEPSEEK_API_KEY:
        raise RuntimeError("Missing DEEPSEEK_API_KEY")
    headers = {"Authorization": f"Bearer {DEEPSEEK_API_KEY}", "Content-Type": "application/json"}
    payload = {"model": model, "messages": messages, "temperature": temperature}
    r = requests.post(f"{DEEPSEEK_BASE_URL}/chat/completions", headers=headers, json=payload, timeout=120)
    r.raise_for_status()
    return r.json()["choices"][0]["message"]["content"]


@st.cache_data(show_spinner=False)
def load_csv(file) -> pd.DataFrame:
    return pd.read_csv(file)


def run_sql(con, q: str) -> pd.DataFrame:
    return con.execute(q).df()


# =========================================================
# Sidebar
# =========================================================
st.sidebar.title("æ•°æ®æ¥æº")
data_source = st.sidebar.radio(
    "é€‰æ‹©æ•°æ®æ¥æº",
    ["ğŸ§ª ä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼ˆæ— éœ€ä¸Šä¼ ï¼‰", "ğŸ“‚ ä¸Šä¼  CSVï¼ˆuser / event / timestampï¼‰"],
    index=0,
    key="data_source",
)

uploaded = None
if data_source.startswith("ğŸ“‚"):
    uploaded = st.sidebar.file_uploader("ä¸Šä¼  CSV æ–‡ä»¶", type=["csv"], key="uploaded_csv")

deep_mode = st.sidebar.toggle("æ·±åº¦åˆ†æ", value=False)
strict_mode = st.sidebar.toggle("ä¸¥æ ¼æ¼æ–—ï¼ˆæŒ‰é¡ºåºï¼‰", value=False)
window_days = st.sidebar.radio("å¯¹æ¯”å‘¨æœŸï¼ˆå¤©ï¼‰", [7, 14, 30], horizontal=True)

# =========================================================
# Main
# =========================================================
st.title("ğŸ“Š äº‹ä»¶æ¼æ–—è‡ªåŠ¨æ´å¯Ÿ")

# Load data
if data_source.startswith("ğŸ§ª"):
    df = make_sample_data()
    st.info("å½“å‰ä½¿ç”¨ï¼šç¤ºä¾‹æ•°æ®ï¼ˆpage_view â†’ click â†’ purchaseï¼‰ï¼Œå¹¶é™„å¸¦ device/country ä½œä¸ºç»´åº¦ç¤ºä¾‹ã€‚")
else:
    if not uploaded:
        st.info("è¯·åœ¨å·¦ä¾§ä¸Šä¼  CSV æ–‡ä»¶")
        st.stop()
    df = load_csv(uploaded)

with st.expander("æ•°æ®é¢„è§ˆ", expanded=False):
    st.dataframe(df.head(20), use_container_width=True)

# Column mapping
cols = {c.lower(): c for c in df.columns}
uid_col = cols.get("user_id") or cols.get("visitorid")
evt_col = cols.get("event")
ts_col = cols.get("timestamp")
if not all([uid_col, evt_col, ts_col]):
    st.error("éœ€è¦åŒ…å« user_idï¼ˆæˆ– visitoridï¼‰/ event / timestamp åˆ—")
    st.stop()

# Funnel steps
st.sidebar.subheader("æ¼æ–—æ­¥éª¤ï¼ˆN-stepï¼Œå¯å¢å¯å‡ï¼‰")
events = sorted(df[evt_col].dropna().astype(str).unique().tolist())
if len(events) < 2:
    st.error("äº‹ä»¶ç§ç±»å¤ªå°‘ï¼ˆ<2ï¼‰ï¼Œæ— æ³•è¿›è¡Œæ¼æ–—åˆ†æã€‚")
    st.stop()

if "steps" not in st.session_state:
    default = events[:3] if len(events) >= 3 else events[:2]
    st.session_state["steps"] = default

btn_c1, btn_c2 = st.sidebar.columns(2)
with btn_c1:
    if st.button("â• æ·»åŠ ä¸€æ­¥", use_container_width=True):
        st.session_state["steps"].append(events[0])
with btn_c2:
    if st.button("â– åˆ é™¤æœ€åä¸€æ­¥", use_container_width=True):
        if len(st.session_state["steps"]) > 2:
            st.session_state["steps"] = st.session_state["steps"][:-1]

new_steps = []
for i, cur in enumerate(st.session_state["steps"]):
    idx = events.index(cur) if cur in events else 0
    val = st.sidebar.selectbox(f"Step {i+1}", events, index=idx, key=f"step_{i}")
    new_steps.append(val)

st.session_state["steps"] = new_steps
steps = st.session_state["steps"]
step_count = len(steps)

if len(set(steps)) < len(steps):
    st.sidebar.warning("å»ºè®®æ¯ä¸€æ­¥é€‰æ‹©ä¸åŒäº‹ä»¶ï¼Œå¦åˆ™æ¼æ–—è§£é‡Šä¼šå˜å¼±ã€‚")

# Breakdown selection
st.sidebar.subheader("æ¼æ–—ç»´åº¦ï¼ˆBreakdownï¼‰")
cands = infer_breakdown_candidates(df, uid_col, evt_col, ts_col)

bd_options = ["ä¸åˆ†ç»„ï¼ˆæ€»ä½“ï¼‰"]
bd_meta = {}
for col, label, reason in cands:
    display = f"{label}ï½œ{col}"
    bd_options.append(display)
    bd_meta[display] = (col, label, reason)

bd_choice = st.sidebar.selectbox("é€‰æ‹©åˆ†ç»„å­—æ®µï¼ˆæœ€å¤š 1 ä¸ªï¼‰", bd_options, index=0)
breakdown_col = None
breakdown_label = None
breakdown_reason = ""

if bd_choice != "ä¸åˆ†ç»„ï¼ˆæ€»ä½“ï¼‰":
    breakdown_col, breakdown_label, breakdown_reason = bd_meta[bd_choice]
    with st.sidebar.expander("ä¸ºä»€ä¹ˆæ¨èè¿™ä¸ªå­—æ®µï¼Ÿ", expanded=False):
        st.write(f"- ç±»å‹ï¼š{classify_dim(breakdown_col)}")
        st.write(f"- ç»Ÿè®¡ï¼š{breakdown_reason}")

# DuckDB
con = duckdb.connect(":memory:")
con.register("events", df)
max_ts = con.execute(f"SELECT MAX(to_timestamp({ts_col}/1000)) FROM events").fetchone()[0]
st.caption(f"æ—¶é—´åŸºå‡†ï¼š{max_ts}ï¼ˆlast_{window_days}d vs prev_{window_days}dï¼‰")

# Overall funnel (always)
sql_overall = funnel_sql_nstep(uid_col, evt_col, ts_col, steps, window_days, strict_mode, breakdown_col=None)
res_all = run_sql(con, sql_overall)
res_all["__o"] = res_all["period"].map({"prev": 0, "last": 1})
res_all = res_all.sort_values("__o").drop(columns="__o").reset_index(drop=True)

st.subheader("ğŸ“ˆ æ¼æ–—å¯¹æ¯”ç»“æœï¼ˆæ€»ä½“ï¼‰")
st.dataframe(res_all, use_container_width=True)

if res_all.shape[0] < 2:
    st.warning("æ€»ä½“æ²¡æœ‰å¾—åˆ° prev/last ä¸¤æœŸæ•°æ®ï¼Œå¯èƒ½æ˜¯æ•°æ®æ—¶é—´è·¨åº¦ä¸è¶³æˆ–äº‹ä»¶è¿‡å°‘ã€‚")
    st.stop()

prev_all, last_all = res_all.iloc[0], res_all.iloc[1]
rates_all, deltas_all = compute_rates_and_deltas(prev_all, last_all, step_count)
worst_k_all, worst_pp_all = find_worst_delta(deltas_all)

th = threshold_pp(int(window_days))
risk_level = level(worst_pp_all, th)
worst_readable_all = pretty_step_label(worst_k_all, steps)
hint = build_hint(worst_pp_all, th)

# Dashboard
st.subheader("ğŸš¨ è‡ªåŠ¨æ´å¯Ÿï¼ˆæ€»ä½“ï¼šæœ¬æœŸ vs ä¸ŠæœŸï¼‰")
st.caption(f"å‘¨æœŸï¼šlast_{window_days}d vs prev_{window_days}dï½œé¢„è­¦é˜ˆå€¼ï¼š{th:.2f} pp")

kcols = st.columns(min(3, step_count))
for i in range(min(3, step_count)):
    with kcols[i]:
        sname = steps[i]
        st.metric(
            f"Step{i+1} ç”¨æˆ·ï¼ˆ{sname}ï¼‰",
            fmt_int(last_all[f"s{i+1}"]),
            fmt_int(int(last_all[f"s{i+1}"]) - int(prev_all[f"s{i+1}"])),
        )

st.divider()

conv_cols = st.columns(3)
with conv_cols[0]:
    if step_count >= 2:
        d = deltas_all["d1_2"]
        st.metric(
            f"{steps[0]} â†’ {steps[1]} è½¬åŒ–ç‡",
            pct(rates_all["r1_2"]),
            f"{pp(d)}  {emoji_from_level(level(d, th))}",
        )
with conv_cols[1]:
    if step_count >= 3:
        d = deltas_all["d2_3"]
        st.metric(
            f"{steps[1]} â†’ {steps[2]} è½¬åŒ–ç‡",
            pct(rates_all["r2_3"]),
            f"{pp(d)}  {emoji_from_level(level(d, th))}",
        )
with conv_cols[2]:
    d = deltas_all[f"d1_{step_count}"]
    st.metric(
        f"{steps[0]} â†’ {steps[-1]} æ€»è½¬åŒ–ç‡",
        pct(rates_all[f"r1_{step_count}"]),
        f"{pp(d)}  {emoji_from_level(level(d, th))}",
    )

st.divider()
left, right = st.columns([1, 2])
with left:
    st.markdown("### ğŸš¦ é¢„è­¦æ€»è§ˆï¼ˆæ€»ä½“ï¼‰")
    st.markdown(f"**æœ€å¤§ä¸‹é™æ­¥éª¤**ï¼š**{worst_readable_all}**ï¼ˆ{worst_pp_all:.2f} ppï¼‰")
    st.markdown(f"**çŠ¶æ€**ï¼š{risk_level}")
with right:
    st.markdown("### ğŸ§­ è¡ŒåŠ¨æç¤ºï¼ˆæ€»ä½“ï¼‰")
    st.info(hint)

# Breakdown funnel (optional)
breakdown_summary_text = ""
if breakdown_col:
    st.subheader(f"ğŸ§© åˆ†ç»„æ¼æ–—ï¼ˆBreakdownï¼š{breakdown_label}ï½œ{breakdown_col}ï¼‰")

    sql_bd = funnel_sql_nstep(uid_col, evt_col, ts_col, steps, window_days, strict_mode, breakdown_col=breakdown_col)
    res_bd = run_sql(con, sql_bd)
    res_bd["__o"] = res_bd["period"].map({"prev": 0, "last": 1})
    res_bd = res_bd.sort_values(["bd", "__o"]).drop(columns="__o").reset_index(drop=True)
    res_bd["bd"] = res_bd["bd"].astype(str).fillna("(null)")

    groups = []
    for g, gdf in res_bd.groupby("bd"):
        if gdf.shape[0] < 2:
            continue
        p = gdf.iloc[0]
        l = gdf.iloc[1]
        rates_g, deltas_g = compute_rates_and_deltas(p, l, step_count)
        wk, wpp = find_worst_delta(deltas_g)
        groups.append(
            {
                "group": g,
                "worst_step": pretty_step_label(wk, steps),
                "worst_pp": round(wpp, 2),
                "status": level(wpp, th),
                **{f"last_s{i+1}": int(l[f"s{i+1}"]) for i in range(step_count)},
                **{f"last_r{i}_{i+1}": round(rates_g[f"r{i}_{i+1}"] * 100, 2) for i in range(1, step_count)},
            }
        )

    if not groups:
        st.info("è¯¥ç»´åº¦åœ¨å½“å‰æ•°æ®ä¸‹æ— æ³•å½¢æˆå®Œæ•´çš„ prev/last ä¸¤æœŸåˆ†ç»„å¯¹æ¯”ã€‚")
    else:
        bd_table = pd.DataFrame(groups).sort_values("worst_pp").reset_index(drop=True)
        top = bd_table.iloc[0]
        breakdown_summary_text = f"ä¸‹é™æœ€ä¸¥é‡çš„åˆ†ç»„æ˜¯ **{top['group']}**ï¼Œå‘ç”Ÿåœ¨ **{top['worst_step']}**ï¼ˆ{top['worst_pp']:.2f} ppï¼Œ{top['status']}ï¼‰ã€‚"
        st.markdown(f"ğŸš¨ {breakdown_summary_text}")

        show_cols = ["group", "status", "worst_pp", "worst_step"]
        for i in range(min(step_count, 4)):
            show_cols.append(f"last_s{i+1}")
        for i in range(1, min(step_count, 4)):
            show_cols.append(f"last_r{i}_{i+1}")

        bd_show = bd_table[show_cols].copy()
        rename_map = {"group": "åˆ†ç»„", "status": "é¢„è­¦", "worst_pp": "æœ€å¤§ä¸‹æ»‘(pp)", "worst_step": "ä¸‹æ»‘æ­¥éª¤"}
        for i in range(min(step_count, 4)):
            rename_map[f"last_s{i+1}"] = f"æœ¬æœŸ Step{i+1} ç”¨æˆ·"
        for i in range(1, min(step_count, 4)):
            rename_map[f"last_r{i}_{i+1}"] = f"æœ¬æœŸ Step{i}â†’{i+1} è½¬åŒ–(%)"
        bd_show = bd_show.rename(columns=rename_map)

        top_group_value = str(top["group"])

        def highlight_top(row):
            if str(row["åˆ†ç»„"]) == top_group_value:
                return ["background-color: rgba(255, 0, 0, 0.08)"] * len(row)
            return [""] * len(row)

        st.dataframe(bd_show.style.apply(highlight_top, axis=1), use_container_width=True)

        with st.expander("æŸ¥çœ‹åˆ†ç»„æ˜ç»†åŸå§‹è¡¨ï¼ˆå«æ›´å¤šæ­¥éª¤/æŒ‡æ ‡ï¼‰", expanded=False):
            st.dataframe(bd_table, use_container_width=True)

# LLM Report
model = REASONER_MODEL if deep_mode else CHAT_MODEL
if "report_cache" not in st.session_state:
    st.session_state.report_cache = {}

report_key = f"{window_days}|{strict_mode}|{deep_mode}|{','.join(steps)}|bd={breakdown_col}|all={int(last_all['s1'])}"

st.subheader("ğŸ§  è¿è¥æ´å¯Ÿæ—¥æŠ¥")
colA, colB = st.columns([1, 3])
with colA:
    gen_report = st.button("ç”Ÿæˆ/åˆ·æ–°æ—¥æŠ¥", type="primary", use_container_width=True)
with colB:
    st.caption("æç¤ºï¼šåˆ‡æ¢å‘¨æœŸ/æ¼æ–—æ­¥éª¤/ç»´åº¦ä¼šå¯¼è‡´é¡µé¢é‡è·‘ï¼›æ—¥æŠ¥å»ºè®®æ‰‹åŠ¨ç”Ÿæˆï¼Œé¿å…é¢‘ç¹è°ƒç”¨æ¨¡å‹ã€‚")

if gen_report:
    deltas_list = []
    for i in range(1, step_count):
        dk = f"d{i}_{i+1}"
        deltas_list.append(f"- Step{i}â†’{i+1}ï¼š{deltas_all[dk]:.2f}pp")
    deltas_list.append(f"- Step1â†’{step_count}ï¼š{deltas_all[f'd1_{step_count}']:.2f}pp")

    prompt = f"""
ä½ æ˜¯äº’è”ç½‘äº§å“è¿è¥åˆ†æåŠ©æ‰‹ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªäº‹ä»¶æ¼æ–—å¯¹æ¯”ï¼ˆæŒ‰ç”¨æˆ·ï¼‰ï¼Œè¯·è¾“å‡ºä¸€ä»½â€œè¿è¥æ´å¯Ÿæ—¥æŠ¥â€ï¼ˆMarkdownï¼‰ï¼Œä¸è¦åé—®ç”¨æˆ·ã€‚

ã€æ¼æ–—å®šä¹‰ã€‘
Steps = {steps}
ä¸¥æ ¼æ¼æ–—ï¼ˆé¡ºåºï¼‰={strict_mode}
å‘¨æœŸï¼šlast_{window_days}d vs prev_{window_days}d
æ—¶é—´åŸºå‡†ï¼š{max_ts}

ã€æ€»ä½“ï¼ˆä¸åˆ†ç»„ï¼‰ç»Ÿè®¡ã€‘
prev/last countsï¼š
{res_all.to_dict(orient="records")}

æ€»ä½“è½¬åŒ–å˜åŒ–ï¼ˆppï¼‰ï¼š
{chr(10).join(deltas_list)}
æœ€å¤§ä¸‹é™æ­¥éª¤ï¼š{worst_readable_all}ï¼ˆ{worst_pp_all:.2f}ppï¼Œ{risk_level}ï¼‰

ã€åˆ†ç»„æ´å¯Ÿï¼ˆå¦‚æœ‰ï¼‰ã€‘
Breakdownå­—æ®µï¼š{breakdown_col or "æ— "}
{breakdown_summary_text or "æ— åˆ†ç»„æˆ–æ— æœ‰æ•ˆåˆ†ç»„å¯¹æ¯”"}

ã€è¾“å‡ºè¦æ±‚ã€‘
å¿…é¡»åŒ…å«ï¼š
## ä¸€å¥è¯ç»“è®º
## å˜åŒ–æœ€å¤§çš„æ­¥éª¤ä¸å½±å“ï¼ˆå…ˆæ€»ä½“ï¼Œå†åˆ†ç»„ï¼‰
## å¯èƒ½åŸå› ï¼ˆå‡è®¾ï¼Œ2-4æ¡ï¼‰
## ä¸‹ä¸€æ­¥æ’æŸ¥ä¸è¿è¥åŠ¨ä½œï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼Œè‡³å°‘5æ¡ï¼Œå¯æ‰§è¡Œï¼‰
"""
    try:
        with st.spinner("ç”Ÿæˆæ—¥æŠ¥ä¸­â€¦ï¼ˆæ·±åº¦åˆ†æä¼šæ›´æ…¢ï¼‰"):
            report = deepseek_chat([{"role": "user", "content": prompt}], model=model)
        st.session_state.report_cache[report_key] = report
    except Exception as e:
        st.error("æ—¥æŠ¥ç”Ÿæˆå¤±è´¥ï¼ˆå¯èƒ½æ˜¯ç½‘ç»œ/é™æµ/Key/è¶…æ—¶ï¼‰ã€‚")
        st.code(str(e))

report = st.session_state.report_cache.get(report_key, "")
if report:
    st.markdown(report)
else:
    st.info("ç‚¹å‡»ä¸Šé¢çš„ã€Œç”Ÿæˆ/åˆ·æ–°æ—¥æŠ¥ã€æ¥ç”Ÿæˆæ´å¯Ÿæ—¥æŠ¥ã€‚")

# Export
st.subheader("ğŸ“¥ å¯¼å‡ºæ—¥æŠ¥")
md = build_export_markdown(
    steps=steps,
    window_days=window_days,
    strict_mode=strict_mode,
    breakdown_col=breakdown_col,
    th=th,
    max_ts=max_ts,
    worst_readable_all=worst_readable_all,
    worst_pp_all=worst_pp_all,
    risk_level=risk_level,
    hint=hint,
    breakdown_summary_text=breakdown_summary_text,
    report=report,
)
fname = f"äº‹ä»¶æ¼æ–—æ´å¯Ÿ_{window_days}d.md"
st.download_button("â¬‡ï¸ ä¸‹è½½ Markdown æ—¥æŠ¥", md.encode("utf-8"), fname)
